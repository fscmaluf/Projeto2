{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "### Fabio Maluf e Matheus Pellizzon\n",
    "\n",
    "###### Produto: Netflix\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instalar UNICODE_EMOJI:\n",
    "\n",
    "Abrir prompt de comando\n",
    "\n",
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "df = pd.read_excel('tweets_netflix_treinamento.xlsx')\n",
    "\n",
    "df.replace(regex=['\\n', '\\t'], value = '', inplace = True) #corrigindo separação entre enter e tab - pt.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "remover = ['?', '!', ',', ';', '.', '”', '“', ')',\n",
    "           '(', '*', '...', ':', '…', '{', '}', '\"',\n",
    "           '\"', '=', \"'\", '•', '|', '-', '/'] #caracteres que devem ser removídos\n",
    "for i in range(len(df['Treinamento'])):\n",
    "    m = ''\n",
    "    tweet = df['Treinamento'][i]\n",
    "    for letra in tweet:\n",
    "        if letra in UNICODE_EMOJI:\n",
    "            m += ' ' + letra  + ' ' #corrigindo espaçamento entre caracteres - pt.2\n",
    "        elif letra not in remover:\n",
    "            m += letra\n",
    "    tweets.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final = []\n",
    "words = ['rt', 'a', 'is', 'me', 'in', 'netflix', 'as', 'it',\n",
    "         'we', 'us', 'of', 'i', 'to', 'the', 'by', 'im', 'so',\n",
    "         'are', 'or', 'has', 'have', 'their', 'that', 'else',\n",
    "         'on', 'be', 'his', 'our', 'you', 'my', 'its', 'for',\n",
    "         \"it’s\", 'this', 'if']\n",
    "for i in tweets:\n",
    "    post = i.split()\n",
    "    palavras = ''\n",
    "    for e in post:\n",
    "        #removendo links, hashtags, @, e demais termos/palavras inúteis\n",
    "        if e[0:4] != 'http' and e[0:1] != '@' and e[:1] != '#' and e not in words:\n",
    "            palavras += '' + e + ' '\n",
    "        elif e in UNICODE_EMOJI:\n",
    "            palavras += '' + e + ''\n",
    "            \n",
    "    tweets_final.append(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love wi noah centineo wtf can him</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stoned watching bed</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ruins anime again making live action bleach smh</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>well today’s day sierra burgess loser finally ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stoned watching bed</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0                 love wi noah centineo wtf can him          0.0\n",
       "1                               stoned watching bed          0.0\n",
       "2   ruins anime again making live action bleach smh          1.0\n",
       "3  well today’s day sierra burgess loser finally ...         0.0\n",
       "4                               stoned watching bed          0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(tweets_final, columns=['Treinamento'])\n",
    "data = data.join(df['Relevância'], how='inner')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tudo = []\n",
    "\n",
    "for tweet in data['Treinamento']:\n",
    "    a = tweet.split(' ')\n",
    "    for palavra in a:\n",
    "        if palavra not in tudo:\n",
    "            tudo.append(palavra)\n",
    "            \n",
    "conta_relevante = 0\n",
    "conta_irrelevante = 0\n",
    "\n",
    "for i in range(len(data['Treinamento'])):\n",
    "    a = data[\"Treinamento\"][i].split(\" \")\n",
    "    if data['Relevância'][i] == 1:\n",
    "        for palavra in a:\n",
    "            conta_relevante += 1\n",
    "    else:\n",
    "        for palavra in a:\n",
    "            conta_irrelevante += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante = {}\n",
    "irrelevante = {}\n",
    "\n",
    "for palavra in tudo:\n",
    "    relevante[palavra] = 1\n",
    "    irrelevante[palavra] = 1\n",
    "    \n",
    "    \n",
    "for i in range(len(data['Treinamento'])):\n",
    "    a = data[\"Treinamento\"][i].split(\" \")\n",
    "    if data['Relevância'][i] == 1:\n",
    "        for palavra in a:\n",
    "            relevante[palavra] += 1\n",
    "    else:\n",
    "        for palavra in a:\n",
    "            irrelevante[palavra] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_relevante = {}\n",
    "prob_irrelevante = {}\n",
    "\n",
    "for palavra in tudo:\n",
    "    prob_relevante[palavra] = relevante[palavra] / (conta_relevante + len(tudo)) \n",
    "    prob_irrelevante[palavra] = irrelevante[palavra] / (conta_irrelevante + len(tudo)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_rel = len(data[data[\"Relevância\"] == 1])\n",
    "tweets_irrel = len(data[data[\"Relevância\"] == 0])\n",
    "\n",
    "prob_tweets_irrel = tweets_irrel / (tweets_irrel + tweets_rel)\n",
    "prob_tweets_rel = tweets_rel / (tweets_irrel + tweets_rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_excel('tweets_netflix_teste.xlsx')\n",
    "\n",
    "df2.replace(regex=['\\n', '\\t'], value = '', inplace = True) #corrigindo separação entre enter e tab - pt.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "remover = ['?', '!', ',', ';', '.', '”', '“', ')',\n",
    "           '(', '*', '...', ':', '…', '{', '}', '\"',\n",
    "           '\"', '=', \"'\", '•', '|', '-', '/'] #caracteres que devem ser removídos\n",
    "for i in range(len(df2['Teste'])):\n",
    "    m = ''\n",
    "    tweet = df2['Teste'][i]\n",
    "    for letra in tweet:\n",
    "        if letra in UNICODE_EMOJI:\n",
    "            m += ' ' + letra  + ' ' #corrigindo espaçamento entre caracteres - pt.2\n",
    "        elif letra not in remover:\n",
    "            m += letra\n",
    "    tweets.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final = []\n",
    "words = words = ['rt', 'a', 'is', 'me', 'in', 'netflix', 'as', 'it',\n",
    "         'we', 'us', 'of', 'i', 'to', 'the', 'by', 'im', 'so',\n",
    "         'are', 'or', 'has', 'have', 'their', 'that', 'else',\n",
    "         'on', 'be', 'his', 'our', 'you', 'my', 'its', 'for',\n",
    "         \"it’s\", 'this', 'if']\n",
    "for i in tweets:\n",
    "    post = i.split()\n",
    "    palavras = ''\n",
    "    for e in post:\n",
    "        #removendo links, hashtags, @, e demais termos/palavras inúteis\n",
    "        if e[0:4] != 'http' and e[0:1] != '@' and e[:1] != '#' and e not in words:\n",
    "            palavras += '' + e + ' '\n",
    "        elif e in UNICODE_EMOJI:\n",
    "            palavras += '' + e + ''\n",
    "            \n",
    "    tweets_final.append(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame(tweets_final, columns=['Teste'])\n",
    "data2 = data2.join(df2['Relevância'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = []\n",
    "\n",
    "for tweet in data2['Teste']:\n",
    "    prob_rel = 1\n",
    "    prob_irrel = 1\n",
    "    palavras = tweet.split(' ')\n",
    "        \n",
    "    for palavra in palavras:\n",
    "        if palavra in prob_relevante:\n",
    "            prob_rel *= prob_relevante[palavra]\n",
    "        else:\n",
    "            prob_rel *= (1 / (conta_relevante + len(tudo)))\n",
    "            \n",
    "    for palavra in palavras:   \n",
    "        if palavra in prob_irrelevante:\n",
    "            prob_irrel *= prob_irrelevante[palavra]\n",
    "        else:\n",
    "            prob_irrel *= (1 / (conta_irrelevante + len(tudo)))\n",
    "            \n",
    "    prob_rel *= prob_tweets_rel\n",
    "    prob_irrel *= prob_tweets_irrel\n",
    "        \n",
    "    if prob_rel > prob_irrel:\n",
    "        previsao.append(1)\n",
    "    else:\n",
    "        previsao.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do classificador é de: 79.0%\n"
     ]
    }
   ],
   "source": [
    "data2['Previsão'] = previsao\n",
    "\n",
    "iguais = data2[data2['Relevância'] == data2['Previsão']]\n",
    "\n",
    "accuracy = len(iguais)/len(data2)\n",
    "\n",
    "print('A acurácia do classificador é de: {}%' .format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de Positivos Falsos: 19.5%\n"
     ]
    }
   ],
   "source": [
    "#Positivos Falsos\n",
    "positivos_falsos = data2[(data2['Previsão'] == 1) & (data2['Relevância'] == 0)]\n",
    "\n",
    "false_p = len(positivos_falsos)/len(data2)\n",
    "\n",
    "print('Porcentagem de Positivos Falsos: {}%' .format(false_p * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de Positivos Verdadeiros: 3.0%\n"
     ]
    }
   ],
   "source": [
    "#Positivos Verdadeiros\n",
    "positivos_verdadeiros = data2[(data2['Previsão'] == 1) & (data2['Relevância'] == 1)]\n",
    "\n",
    "true_p = len(positivos_verdadeiros)/len(data2)\n",
    "\n",
    "print('Porcentagem de Positivos Verdadeiros: {}%' .format(true_p * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de Negativos Verdadeiros: 76.0%\n"
     ]
    }
   ],
   "source": [
    "#Negativos Verdadeiros\n",
    "negativos_verdadeiros = data2[(data2['Previsão'] == 0) & (data2['Relevância'] == 0)]\n",
    "\n",
    "true_n = len(negativos_verdadeiros)/len(data2)\n",
    "\n",
    "print('Porcentagem de Negativos Verdadeiros: {}%' .format(true_n * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de Negativos Falsos: 1.5%\n"
     ]
    }
   ],
   "source": [
    "negativos_falsos = data2[(data2['Previsão'] == 0) & (data2['Relevância'] == 1)]\n",
    "\n",
    "false_n = len(negativos_falsos)/len(data2)\n",
    "\n",
    "print('Porcentagem de Negativos Falsos: {}%' .format(false_n * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparação Qualitativa:**\n",
    "\n",
    "O classificador apresentou uma precisão de 79%, indicando 76% de negativos verdadeiros, ou seja, tweets classificados como irrelevantes que realmente são irrelevantes e 3% de positivos verdadeiros, ou seja, tweets classificasdos como relevantes que realmente são relevantes. Os outros 21% foram classificações erradas, onde 19.5% são positivos falsos e 1.5% de negativos falsos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problemas:**\n",
    "\n",
    "A utilização de Naive Bayes para a classificação de sentimentos acaba tendo uma perfomance ruim, pois a a probabilidade das palavras multiplicadas não são tão relevantes quanto a ordem em que elas são escritas, fazendo com que frases com dupla negação ou sarcasmo não possam ser classificadas corretamente, por exemplo.\n",
    "\n",
    "Não se pode alimentar a própria base de dados de Treinamento usando o classificador, pois o espaço de amostras que nosso classificador apresenta é a base de tweets de Treinamento. Assim, não tem acesso a mais informações não conseguindo analisar o contexto das coisas, levando a uma classificação errada de dupla negação, sarcasmo e ironia.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plano de Expansão:**\n",
    "\n",
    "Inicialmente apresentamos um resultado com uma alta precisão de nosso classificador. Essa precisão foi obtida com apenas a retirada de algumas palavras da nossa base de dados. Com isso poderiamos fazer uma melhor análise de palavras para gerar uma filtragem que apresente palavras com maior peso para a classificação de relevância gerando resultados mais precisos.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes fora do Projeto:**\n",
    "\n",
    "A utilização de Naive Bayes em geral é usada para a classificação. Saindo da classificação de palavras podemos usá-lo para classificar qualquer coisa, como por exemplo animais, classificar o animal de acordo com as características apresentadas, atribuir tópicos de um texto livre, classificar o texto em 'esportes', 'política', etc. ou até mesmo, classificação de um cliente em chance de ele pagar um empréstimo feito a ele.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
